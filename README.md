# finetune-a-google-ViT-easily
A simple set of scripts and little tools to finetune a Google ViT model on whatever set of images you might have.

All code in this repo was generated by Google Gemini 2.5 Flash Preview 04-17. I just wanted a quick way to finetune a ViT to categorize images and this is what worked for me.

This code also assumes that you are using an ImageFolder dataset - that will be explained later

## Usage

Install `transformers datasets accelerate torch torchvision scikit-learn pillow` into a venv.
As of 7/18/2025 the versions of each package I used were `transformers==4.52.4 datasets==4.0.0 accelerate==1.8.1 torch==2.9.0.dev20250711+rocm6.3 torchvision==0.24.0.dev20250712+rocm6.3 scikit-learn==1.7.1 pillow==11.2.1`

Organize your images into a structure similar to the graph. It is important to make a validation dataset so you can observe the effectiveness of your training while it is going on (i.e., if your accuracy isn't improving after a few epochs, you aren't helping your model much). Your validation dataset does not need to be equal in size to your training dataset - make sure it is big enough to cover any edge cases you can think of but not big enough to cause a big break in training time.

Making an ImageFolder Dataset:

The images should go into a folder with the tag name they are associated with. Make sure that the folder names match between your training dataset and validation folders!
```
dataset/
├── Figures/
│   ├── New-gundam-figurine.png
│   ├── 1342-data.jpg
│   └── ...
├── Models/
│   ├── my new tamiya plane.jpeg
│   ├── fa7e786d8.png
│   └── ...
└── Unrelated/
    ├── my_dinner_from_last_night.png
    ├── sniffles.jpeg
    └── ...
validation/
├── Figures/
│   ├── Known_good_image.png
│   └── ...
├── Models/
│   ├── model-valid.jpeg
│   └── ...
└── Unrelated/
    ├── ice_cream_stand.jpeg
    └── ...
output/
```
Use the tools in this repo's tools folder to clean up your dataset if desired. I had issues with some errant 0-byte files getting into the dataset and validation images - use `0byteKiller.py` to remove them. I also had some HTML files from a cloudflare ratelimit get into my images, so use `nonImageRemover.py` to double check if youtr images are actually readable. If you want to pull some images randomly from your dataset or to create a validation dataset, use `randomFileChooser.py` to extract however many files you want from a folder (edit the number of files to move at the bottom of the script). 

Edit `train.py` to point it at your dataset and validation folder(s), and optionally edit `per_device_train_batch_size` and `per_device_eval_batch_size` up or down depending on your GPU. I use a 7900xtx and a batch size of 16 worked the fastest for me. Optionally, uncomment `bf16=True` if you want to train with mixed precision. I commented out `learning_rate` because the default value got the best results for me. Change it if you need to. Change `num_train_epochs` if you want to train for longer/shorter depending on your dataset and accuracy results.

When an epoch is reached and/or when training ends, checkpoints and model files will be output in `output/` by default. Use `testViT.py` to run inference using one of the checkpoints on a specified folder of images.
